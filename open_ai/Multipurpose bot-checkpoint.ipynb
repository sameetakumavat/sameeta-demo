{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c336f2d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "api_key found\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv(r'C:\\Users\\sakumavat\\Documents\\Open AI practice code\\.env'))\n",
    "\n",
    "api_key = os.environ.get('OPENAI_API_KEY')\n",
    "if api_key == None:\n",
    "    print(\"api_key not found\")\n",
    "else:\n",
    "    print(\"api_key found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc8b143d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080a1201",
   "metadata": {},
   "source": [
    "# Summarize AI bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec5d2ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_model = \"gpt-3.5-turbo-0301\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5cc96280",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "def summarize(text, word_limit=40, model=llm_model):\n",
    "\n",
    "    # can change prompt accordingly as per need\n",
    "    prompt = f\"\"\"\n",
    "    Summarize the text delimited by triple backticks in at most {word_limit} words.\n",
    "    ```{text}```\n",
    "    \"\"\"\n",
    "    \n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0.8\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "36085429",
   "metadata": {},
   "outputs": [],
   "source": [
    "#example 1\n",
    "text = f\"\"\"Revolutionizing Natural Language Processing Introduction In the rapidly evolving field of Natural Language \n",
    "Processing (NLP), Hugging Face has emerged as a prominent and innovative force. This article will explore the story and \n",
    "significance of Hugging Face, a company that has made remarkable contributions to NLP and AI as a whole. From its \n",
    "inception to its role in democratizing AI, Hugging Face has left an indelible mark on the industry.  \n",
    "The Birth of Hugging Face Hugging Face was founded in 2016 by Clément Delangue, Julien Chaumond, and Thomas Wolf. \n",
    "The name Hugging Face was chosen to reflect the company's mission of making AI models more accessible and friendly to \n",
    "humans, much like a comforting hug. Initially, they began as a chatbot company but later shifted their focus to NLP, \n",
    "driven by their belief in the transformative potential of this technology.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f105e627",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = summarize(text, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "18c083ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The article explores the significance of Hugging Face as a prominent and innovative force in the field of Natural Language Processing (NLP), from its inception to its role in democratizing AI.\n"
     ]
    }
   ],
   "source": [
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4759dfa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(res.split( ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4a12066e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example 2\n",
    "text_2 = \"\"\"Artificial Intelligence (AI) stands at the forefront of technological innovation, reshaping the \n",
    "landscape of industries and human interaction. In recent years, AI has made remarkable strides, becoming a driving \n",
    "force behind transformative advancements. Its algorithms analyze vast datasets, unlocking insights that were once \n",
    "unimaginable. From personalized recommendations on streaming platforms to autonomous vehicles navigating complex \n",
    "environments, AI's impact is pervasive.\n",
    "However, with great promise comes ethical considerations. The rapid evolution of AI raises questions \n",
    "about privacy, bias, and accountability. Striking the right balance between technological progress and ethical \n",
    "safeguards is crucial for a harmonious integration of AI into society.\n",
    "In healthcare, AI aids diagnosis and treatment planning, revolutionizing patient care. Moreover, AI-driven virtual \n",
    "assistants streamline daily tasks, enhancing productivity and efficiency. As we navigate the complex terrain of AI \n",
    "development, collaboration between industry, policymakers, and ethicists is essential to ensure responsible and equitable \n",
    "deployment.\n",
    "Looking ahead, AI holds the potential to address global challenges, from climate change to healthcare disparities. \n",
    "Its trajectory hinges on ethical frameworks, continual innovation, and a collective commitment to harnessing its power \n",
    "for the betterment of humanity.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "50b3d033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artificial Intelligence (AI) is transforming industries and human interaction through analysis of vast datasets, enabling personalized recommendations and autonomous vehicles. However, ethical considerations such as privacy, bias, and accountability must be addressed for a harmonious integration of AI into society. In healthcare, AI aids diagnosis and treatment planning, and AI-driven virtual assistants enhance productivity and efficiency. Collaboration between industry, policymakers, and ethicists is crucial to ensure the responsible and equitable deployment of AI. The potential for AI to address global challenges such as climate change and healthcare disparities relies on ethical frameworks and continual innovation.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res_2 = summarize(text_2, 80)\n",
    "print(res_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ca3e1b25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(res_2.split( ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b972193",
   "metadata": {},
   "source": [
    "# Extract AI bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d2575c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_model = \"gpt-3.5-turbo-0301\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d250bc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "def extract_topic(text, word_limit=1, model=llm_model):\n",
    "\n",
    "    # can change prompt accordingly as per need\n",
    "    prompt = f\"\"\"\n",
    "    Identify the main topic of the text provided which is delimited by triple backticks in {word_limit} words: \n",
    "    text: '''{text}'''\n",
    "    \"\"\"\n",
    "    \n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0.3\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2970de18",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Python is a general-purpose, high-level programming language. It is used for web development, software development, mathematics, system scripting, and much more. Python is an interpreted language, which means that it does not need to be compiled before it can be run. This makes it very easy to use for beginners.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9ed852f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Python programming language.'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_topic(text, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4e8445",
   "metadata": {},
   "source": [
    "# Rewrite AI bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f6fc16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "def transalator(text, lang='english', model=llm_model):\n",
    "\n",
    "    # can change prompt accordingly as per need\n",
    "    prompt = f\"\"\"\n",
    "    Identify and translate the following  text to {lang} language:\n",
    "    ```{text}```\n",
    "    Write your response in following format:\n",
    "    original language: \\n\n",
    "    translated language: \\n\n",
    "    translated text: response\n",
    "    \"\"\"\n",
    "    \n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0.3\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a6fcb1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_2 = 'Mi monitor tiene píxeles que no se iluminan.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "451ee767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original language: Spanish\n",
      "\n",
      "translated language: English\n",
      "\n",
      "translated text: My monitor has pixels that do not light up.\n"
     ]
    }
   ],
   "source": [
    "res = transalator(text_2, 'english')\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d02e18fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_3 = \"I am so hungry\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "7a224c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original language: English\n",
      "\n",
      "translated language: Hindi\n",
      "\n",
      "translated text: मुझे बहुत भूख लगी है। (Mujhe bahut bhook lagi hai.)\n"
     ]
    }
   ],
   "source": [
    "res_2 = transalator(text_3, 'hindi')\n",
    "print(res_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40dadb05",
   "metadata": {},
   "source": [
    "# Generate AI bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "dfdeaf38",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "def generate_mails(review, model=llm_model):\n",
    "\n",
    "    # can change prompt accordingly as per need\n",
    "    prompt = f\"\"\"\n",
    "    You are a customer service AI assistant. Your task is to send an email reply to a valued customer.\n",
    "    Given the customer email delimited by ```, Generate a reply to thank the customer for their review.\n",
    "    Identify the sentiment and if the sentiment is positive or neutral, thank them for their review.\n",
    "    If the sentiment is negative, apologize and suggest that they can reach out to customer service. \n",
    "    Make sure to use specific details from the review. Write in a concise and professional tone.\n",
    "    Sign the email as `AI customer agent`.\n",
    "    Customer review: ```{review}```\n",
    "    \"\"\"\n",
    "    \n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0.3\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "1765dcd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "review = f\"\"\"\n",
    "So, they still had the 17 piece system on seasonal sale for around $49 in the month of November, about half off, but for some reason (call it price gouging) \\\n",
    "around the second week of December the prices all went up to about anywhere from between $70-$89 for the same system. And the 11 piece system went up around $10 or \\\n",
    "so in price also from the earlier sale price of $29. So it looks okay, but if you look at the base, the part where the blade locks into place doesn’t look as good \\\n",
    "as in previous editions from a few years ago, but I plan to be very gentle with it (example, I crush very hard items like beans, ice, rice, etc. in the \\ \n",
    "blender first then pulverize them in the serving size I want in the blender then switch to the whipping blade for a finer flour, and use the cross cutting blade first when making smoothies, then use the flat blade \\\n",
    "if I need them finer/less pulpy). Special tip when making smoothies, finely cut and freeze the fruits and vegetables (if using spinach-lightly stew soften the \\ \n",
    "spinach then freeze until ready for use-and if making sorbet, use a small to medium sized food processor) that you plan to use that way you can avoid adding so \\\n",
    "much ice if at all-when making your smoothie. After about a year, the motor was making a funny noise. I called customer service but the warranty expired \\\n",
    "already, so I had to buy another one. FYI: The overall quality has gone done in these types of products, so they are kind of counting on brand recognition and \n",
    "consumer loyalty to maintain sales. Got it in about two days.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "f81e1ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dear Valued Customer,\n",
      "\n",
      "Thank you for taking the time to leave a review. We appreciate your feedback and are glad to hear that you were able to take advantage of our seasonal sale. We apologize for any confusion regarding the pricing of our products. Our prices are subject to change based on various factors, including demand and availability.\n",
      "\n",
      "We are sorry to hear that you experienced an issue with the motor of your previous product. We understand how frustrating this can be and we apologize for any inconvenience this may have caused. If you have any further concerns or questions, please do not hesitate to reach out to our customer service team for assistance.\n",
      "\n",
      "Thank you again for your review and for choosing our products. We value your loyalty and hope to continue providing you with quality products in the future.\n",
      "\n",
      "Best regards,\n",
      "\n",
      "AI customer agent\n"
     ]
    }
   ],
   "source": [
    "result = generate_mails(review)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "784a65b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lamp_review = \"\"\"\n",
    "Needed a nice lamp for my bedroom, and this one had additional storage and not too high of a price point. \\\n",
    "Got it fast.  The string to our lamp broke during the transit and the company happily sent over a new one. \\\n",
    "Came within a few days as well. It was easy to put together.  I had a missing part, so I contacted their \\\n",
    "support and they very quickly got me the missing piece! Lumina seems to me to be a great company that cares \\\n",
    "about their customers and products!!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "75522bbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dear Valued Customer,\n",
      "\n",
      "Thank you for taking the time to share your experience with us. We are thrilled to hear that you found our lamp to be a great addition to your bedroom and that our team was able to assist you promptly with the string and missing part issues.\n",
      "\n",
      "At Lumina, we strive to provide our customers with high-quality products and exceptional customer service. Your feedback is greatly appreciated and will be shared with our team.\n",
      "\n",
      "We are glad to hear that you had a positive experience with our company and we hope to have the opportunity to serve you again in the future. If you ever need any assistance, please do not hesitate to reach out to our customer service team.\n",
      "\n",
      "Thank you again for choosing Lumina!\n",
      "\n",
      "Best regards,\n",
      "\n",
      "AI customer agent\n"
     ]
    }
   ],
   "source": [
    "result_2 = generate_mails(lamp_review)\n",
    "print(result_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae1452a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
